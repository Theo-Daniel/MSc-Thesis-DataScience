{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyMmbd8wbXVfw/pFnw4apk+H",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Theo-Daniel/MSc-Thesis-DataScience/blob/main/Copy_of_Thesis_Final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DATASET"
      ],
      "metadata": {
        "id": "zqPeES8XU8lT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "u0yICAnSU5rW"
      },
      "outputs": [],
      "source": [
        "#from google.colab import drive\n",
        "#drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "cancer_df = pd.read_csv('/content/drive/My Drive/Thesis2/Cancer.txt', sep='\\t', index_col=0)\n",
        "normal_df = pd.read_csv('/content/drive/My Drive/Thesis2/Normal.txt', sep='\\t', index_col=0)"
      ],
      "metadata": {
        "id": "9Xqr-130VDJ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PREPROCESSING"
      ],
      "metadata": {
        "id": "bTOTwmvrVRLg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TRANSPOSE (samples = rows, genes = columns), TARGET LABELS"
      ],
      "metadata": {
        "id": "iPa77zZjVbJn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cancer_df = cancer_df.T  # transpose: samples = rows, genes = columns\n",
        "cancer_df['label'] = 1   # mark as cancer\n",
        "\n",
        "normal_df = normal_df.T\n",
        "normal_df['label'] = 0   # mark as normal\n",
        "\n",
        "# Combine the two datasets\n",
        "combined_df = pd.concat([cancer_df, normal_df], axis=0)\n",
        "\n",
        "# Split into features and labels\n",
        "X = combined_df.drop('label', axis=1)\n",
        "y = combined_df['label']\n",
        "\n",
        "print(f\"Dataset shape: {X.shape}, Labels: {y.value_counts().to_dict()}\")"
      ],
      "metadata": {
        "id": "bP0ZJbstVN4_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create backup copies of features and labels\n",
        "X_orig = X.copy()\n",
        "y_orig = y.copy()"
      ],
      "metadata": {
        "id": "DuZvam4SVezV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DATASET ANALYSIS, LOG TRANSFORM, NORMALISATION"
      ],
      "metadata": {
        "id": "H6seFWJoVid8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 1) Check for missing values\n",
        "missing_counts = X.isnull().sum().sum()\n",
        "print(f\"Total missing values: {missing_counts:,}\")\n",
        "\n",
        "# (Optional) Impute / drop if needed\n",
        "# X = X.fillna(0)\n",
        "# X = X.dropna()\n",
        "\n",
        "# 2) Basic statistics (raw scale)\n",
        "print(\"Before transformation:\")\n",
        "print(X.describe().T[['mean', 'std', 'min', 'max']].head())\n",
        "\n",
        "# 3) Clean histograms for the first 5 genes (no overlap)\n",
        "first_cols = list(X.columns[:5])\n",
        "fig_axes = X[first_cols].hist(\n",
        "    bins=50,\n",
        "    layout=(2, 3),       # 2 rows x 3 cols -> room for 5 plots\n",
        "    figsize=(12, 6),\n",
        "    sharex=False,\n",
        "    sharey=False,\n",
        "    grid=False\n",
        ")\n",
        "axes = np.asarray(fig_axes)\n",
        "\n",
        "# Remove any unused subplot (since we created a 2x3 grid for 5 plots)\n",
        "for ax in axes.ravel()[len(first_cols):]:\n",
        "    ax.remove()\n",
        "\n",
        "# Add a neat overall title and tighten layout\n",
        "fig = axes.ravel()[0].get_figure()\n",
        "fig.suptitle(\"Raw Expression Distributions (First 5 Genes)\", y=1.02)\n",
        "fig.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# 4) Log transform if clearly not already in log scale\n",
        "if X.values.max() > 100:\n",
        "    X = np.log2(X + 1)\n",
        "    print(\"Applied log2(x + 1) transformation.\")\n",
        "\n",
        "# 5) Standardize features (mean=0, std=1) using TRAIN fit only in your pipeline\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# 6) Back to DataFrame (optional)\n",
        "X_scaled_df = pd.DataFrame(X_scaled, columns=X.columns, index=X.index)\n",
        "\n",
        "print(\"After standardization:\")\n",
        "print(X_scaled_df.describe().T[['mean', 'std']].head())"
      ],
      "metadata": {
        "id": "UkeJaIBkXfx4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# FEATURE SELECTION"
      ],
      "metadata": {
        "id": "ctiUqdZdaga1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. LASSO"
      ],
      "metadata": {
        "id": "LprRi5Ekak39"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegressionCV\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "import numpy as np\n",
        "\n",
        "# Define stratified CV\n",
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# Fit Lasso (L1) Logistic Regression with CV\n",
        "lasso = LogisticRegressionCV(\n",
        "    Cs=[0.01, 0.1, 1],\n",
        "    penalty='l1',\n",
        "    solver='saga',\n",
        "    max_iter=5000,\n",
        "    cv=cv,\n",
        "    scoring='accuracy',\n",
        "    random_state=42,\n",
        "    n_jobs=-1\n",
        ")\n",
        "lasso.fit(X_scaled, y)\n",
        "\n",
        "# Get absolute coefficient values\n",
        "coefs = np.abs(lasso.coef_[0])\n",
        "gene_names = X.columns\n",
        "\n",
        "# Create a DataFrame of genes and their Lasso coefficients\n",
        "lasso_df = pd.DataFrame({'gene': gene_names, 'coef': coefs})\n",
        "lasso_df = lasso_df[lasso_df['coef'] > 0]  # Keep only non-zero\n",
        "lasso_df = lasso_df.sort_values(by='coef', ascending=False).head(50)\n",
        "\n",
        "# Get the top 50 genes\n",
        "top_50_genes_lasso = lasso_df['gene'].tolist()\n",
        "\n",
        "print(\"Top 5 genes by Lasso:\")\n",
        "print(lasso_df.head())\n",
        "\n",
        "# Subset original scaled X to only top 50 features\n",
        "X_lasso_top50 = X_scaled_df[top_50_genes_lasso]"
      ],
      "metadata": {
        "id": "DAirJr1oaHOe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. RFE"
      ],
      "metadata": {
        "id": "YtH-2QIIawJw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.feature_selection import RFE\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "import numpy as np\n",
        "\n",
        "# Initialize Random Forest\n",
        "rf = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
        "\n",
        "# Set up Stratified K-Fold (5 splits)\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# Initialize array to hold support masks across folds\n",
        "support_matrix = np.zeros(X_scaled_df.shape[1])\n",
        "\n",
        "# Loop through each fold and apply RFE\n",
        "for train_idx, val_idx in skf.split(X_scaled_df, y):\n",
        "    X_train, y_train = X_scaled_df.iloc[train_idx], y.iloc[train_idx]\n",
        "\n",
        "    # Apply RFE on training set only\n",
        "    rfe = RFE(estimator=rf, n_features_to_select=50, step=0.05)\n",
        "    rfe.fit(X_train, y_train)\n",
        "\n",
        "    # Add boolean mask (True = selected) to matrix\n",
        "    support_matrix += rfe.support_\n",
        "\n",
        "# Rank genes by frequency of selection across folds\n",
        "feature_counts = pd.Series(support_matrix, index=X_scaled_df.columns)\n",
        "top_50_genes_rfe = feature_counts.sort_values(ascending=False).head(50).index.tolist()\n",
        "\n",
        "# Print top 5 genes\n",
        "print(\"Top 5 genes by RFE with stratified sampling:\")\n",
        "print(top_50_genes_rfe[:5])\n",
        "\n",
        "# Create final reduced feature matrix\n",
        "X_rfe_top50 = X_scaled_df[top_50_genes_rfe]"
      ],
      "metadata": {
        "id": "OSrhRf3naoIb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SAVE AS CSV"
      ],
      "metadata": {
        "id": "E-KHfoE8Zrt-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# ------------------- STEP 1: Define reusable function -------------------\n",
        "def create_selected_gene_df_with_values(gene_list, value_dict, scaled_df):\n",
        "    \"\"\"\n",
        "    Given a list of selected genes, a dictionary of gene:value (importance),\n",
        "    and the original scaled DataFrame, return:\n",
        "    - selected_df: subset with only selected genes\n",
        "    - value_series: Series of importance values indexed by gene\n",
        "    \"\"\"\n",
        "    selected_df = scaled_df[gene_list].copy()\n",
        "    value_series = pd.Series({gene: value_dict[gene] for gene in gene_list})\n",
        "    return selected_df, value_series\n",
        "\n",
        "# ------------------- STEP 2: Lasso output -------------------\n",
        "# Assuming: top_50_genes_lasso, lasso_df, X_scaled_df already exist\n",
        "\n",
        "# Create dictionary: gene -> coefficient\n",
        "lasso_coef_dict = dict(zip(lasso_df['gene'], lasso_df['coef']))\n",
        "\n",
        "# Create reduced DataFrame and coefficient series\n",
        "X_lasso_top50_df, lasso_coef_series = create_selected_gene_df_with_values(\n",
        "    top_50_genes_lasso, lasso_coef_dict, X_scaled_df\n",
        ")\n",
        "\n",
        "# Save to CSV:\n",
        "X_lasso_top50_df.to_csv(\"Lasso_Selected_Genes.csv\")\n",
        "lasso_coef_series.to_csv(\"Lasso_Coefficients.csv\")\n",
        "\n",
        "# ------------------- STEP 3: RFE output -------------------\n",
        "# Assuming: top_50_genes_rfe, feature_counts, X_scaled_df already exist\n",
        "\n",
        "# Create dictionary: gene -> selection count\n",
        "rfe_importance_dict = feature_counts.to_dict()\n",
        "\n",
        "# Create reduced DataFrame and selection frequency series\n",
        "X_rfe_top50_df, rfe_importance_series = create_selected_gene_df_with_values(\n",
        "    top_50_genes_rfe, rfe_importance_dict, X_scaled_df\n",
        ")\n",
        "\n",
        "# Save to CSV:\n",
        "X_rfe_top50_df.to_csv(\"RFE_Selected_Genes.csv\")\n",
        "rfe_importance_series.to_csv(\"RFE_SelectionFrequency.csv\")"
      ],
      "metadata": {
        "id": "poGa80WQZunn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LASSO, RFE SELECTED FEATURES"
      ],
      "metadata": {
        "id": "8dL_7J_LZb57"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Lasso - Top 10 Genes (Expression Values):\")\n",
        "print(X_lasso_top50_df.head(10))\n",
        "\n",
        "print(\"\\nLasso - Top 10 Gene Coefficients:\")\n",
        "print(lasso_coef_series.head(10))"
      ],
      "metadata": {
        "id": "JXu7QA2kZjzD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"RFE - Top 10 Genes (Expression Values):\")\n",
        "print(X_rfe_top50_df.head(10))\n",
        "\n",
        "print(\"\\nRFE - Top 10 Gene Selection Frequencies:\")\n",
        "print(rfe_importance_series.head(10))"
      ],
      "metadata": {
        "id": "XxgsO_6RZnX7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# BINARY CLASSIFICATION (Tumour VS Normal)"
      ],
      "metadata": {
        "id": "BwAzCYKdZ-mP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. LOGISTIC REGRESSION"
      ],
      "metadata": {
        "id": "dnfmNVEAawt9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, classification_report\n",
        "import pandas as pd\n",
        "\n",
        "# Split both Lasso & RFE feature sets using stratified sampling\n",
        "X_train_lasso, X_test_lasso, y_train, y_test = train_test_split(\n",
        "    X_lasso_top50, y, test_size=0.2, stratify=y, random_state=42\n",
        ")\n",
        "\n",
        "X_train_rfe, X_test_rfe, _, _ = train_test_split(\n",
        "    X_rfe_top50, y, test_size=0.2, stratify=y, random_state=42\n",
        ")\n",
        "\n",
        "# Evaluation function (includes prediction breakdown)\n",
        "def evaluate_model(model, X_test, y_test, name=\"Model\"):\n",
        "    y_pred = model.predict(X_test)\n",
        "    y_proba = model.predict_proba(X_test)[:, 1]  # Class 1 (cancer) probability\n",
        "\n",
        "    print(f\"\\nEvaluation Report for {name}\")\n",
        "    print(\"Accuracy :\", accuracy_score(y_test, y_pred))\n",
        "    print(\"Precision:\", precision_score(y_test, y_pred))\n",
        "    print(\"Recall   :\", recall_score(y_test, y_pred))\n",
        "    print(\"F1 Score :\", f1_score(y_test, y_pred))\n",
        "    print(\"ROC AUC  :\", roc_auc_score(y_test, y_proba))\n",
        "    print(\"\\nClassification Report:\")\n",
        "    print(classification_report(y_test, y_pred))\n",
        "\n",
        "    print(\"\\nðŸ”¬ Prediction breakdown (first 20 samples):\")\n",
        "    breakdown = pd.DataFrame({\n",
        "        'Actual Label': y_test.values,\n",
        "        'Predicted Label': y_pred,\n",
        "        'Cancer Prob (class=1)': y_proba\n",
        "    })\n",
        "    print(breakdown.head(20))\n",
        "\n",
        "# Train & evaluate Logistic Regression on Lasso features\n",
        "lr_lasso = LogisticRegression(max_iter=5000, random_state=42)\n",
        "lr_lasso.fit(X_train_lasso, y_train)\n",
        "evaluate_model(lr_lasso, X_test_lasso, y_test, name=\"Logistic Regression (Lasso Features)\")\n",
        "\n",
        "# Train & evaluate Logistic Regression on RFE features\n",
        "lr_rfe = LogisticRegression(max_iter=5000, random_state=42)\n",
        "lr_rfe.fit(X_train_rfe, y_train)\n",
        "evaluate_model(lr_rfe, X_test_rfe, y_test, name=\"Logistic Regression (RFE Features)\")"
      ],
      "metadata": {
        "id": "yft-AcdqZ6eb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. SVM"
      ],
      "metadata": {
        "id": "3VzDrkWMbA8t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, classification_report\n",
        "\n",
        "# Helper function to evaluate models\n",
        "def evaluate_model(model, X_test, y_test, name=\"Model\"):\n",
        "    y_pred = model.predict(X_test)\n",
        "    y_proba = model.decision_function(X_test)  # SVM: use decision_function for probabilities\n",
        "\n",
        "    print(f\"\\n Evaluation Report for {name}\")\n",
        "    print(\"Accuracy :\", accuracy_score(y_test, y_pred))\n",
        "    print(\"Precision:\", precision_score(y_test, y_pred))\n",
        "    print(\"Recall   :\", recall_score(y_test, y_pred))\n",
        "    print(\"F1 Score :\", f1_score(y_test, y_pred))\n",
        "    print(\"ROC AUC  :\", roc_auc_score(y_test, y_proba))\n",
        "    print(\"\\nClassification Report:\")\n",
        "    print(classification_report(y_test, y_pred))\n",
        "\n",
        "    # Print predicted labels alongside actual labels\n",
        "    print(\"\\n Prediction breakdown (first 20 samples):\")\n",
        "    results_df = pd.DataFrame({\n",
        "        'Actual Label': y_test.values,\n",
        "        'Predicted Label': y_pred,\n",
        "        'Decision Score (Cancer=1)': y_proba\n",
        "    })\n",
        "    print(results_df.head(20))\n",
        "\n",
        "# SVM with Lasso Features\n",
        "svm_lasso = SVC(kernel='linear', probability=True, random_state=42)\n",
        "svm_lasso.fit(X_train_lasso, y_train)\n",
        "evaluate_model(svm_lasso, X_test_lasso, y_test, name=\"SVM (Lasso Features)\")\n",
        "\n",
        "# SVM with RFE Features\n",
        "svm_rfe = SVC(kernel='linear', probability=True, random_state=42)\n",
        "svm_rfe.fit(X_train_rfe, y_train)\n",
        "evaluate_model(svm_rfe, X_test_rfe, y_test, name=\"SVM (RFE Features)\")"
      ],
      "metadata": {
        "id": "sr_TPcWRbD8e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. RANDOM FOREST"
      ],
      "metadata": {
        "id": "yYXuvZpJbVwr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Train-test split using saved variables\n",
        "X_train_lasso, X_test_lasso, y_train, y_test = train_test_split(\n",
        "    X_lasso_top50_df, y, test_size=0.2, stratify=y, random_state=42\n",
        ")\n",
        "\n",
        "X_train_rfe, X_test_rfe, _, _ = train_test_split(\n",
        "    X_rfe_top50_df, y, test_size=0.2, stratify=y, random_state=42\n",
        ")\n",
        "\n",
        "\n",
        "# Evaluation function\n",
        "def evaluate_model(model, X_test, y_test, name=\"Model\"):\n",
        "    y_pred = model.predict(X_test)\n",
        "    y_proba = model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "    print(f\"\\nEvaluation Report for {name}\")\n",
        "    print(\"Accuracy :\", accuracy_score(y_test, y_pred))\n",
        "    print(\"Precision:\", precision_score(y_test, y_pred))\n",
        "    print(\"Recall   :\", recall_score(y_test, y_pred))\n",
        "    print(\"F1 Score :\", f1_score(y_test, y_pred))\n",
        "    print(\"ROC AUC  :\", roc_auc_score(y_test, y_proba))\n",
        "    print(\"\\nClassification Report:\")\n",
        "    print(classification_report(y_test, y_pred))\n",
        "\n",
        "    print(\"\\nPrediction breakdown (first 20 samples):\")\n",
        "    prediction_df = pd.DataFrame({\n",
        "        'Actual Label': y_test.values,\n",
        "        'Predicted Label': y_pred,\n",
        "        'Cancer Probability (class=1)': y_proba\n",
        "    })\n",
        "    print(prediction_df.head(20))\n",
        "\n",
        "# Train & evaluate Random Forest with Lasso features\n",
        "rf_lasso = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
        "rf_lasso.fit(X_train_lasso, y_train)\n",
        "evaluate_model(rf_lasso, X_test_lasso, y_test, name=\"Random Forest (Lasso Features)\")\n",
        "\n",
        "# Train & evaluate Random Forest with RFE features\n",
        "rf_rfe = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
        "rf_rfe.fit(X_train_rfe, y_train)\n",
        "evaluate_model(rf_rfe, X_test_rfe, y_test, name=\"Random Forest (RFE Features)\")"
      ],
      "metadata": {
        "id": "CvjoevShbRA6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. XGBOOST"
      ],
      "metadata": {
        "id": "kG7TAuPfbqRQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, classification_report\n",
        "\n",
        "# Evaluation function (same for all models)\n",
        "def evaluate_model(model, X_test, y_test, name=\"Model\"):\n",
        "    y_pred = model.predict(X_test)\n",
        "    y_proba = model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "    print(f\"\\n Evaluation Report for {name}\")\n",
        "    print(\"Accuracy :\", accuracy_score(y_test, y_pred))\n",
        "    print(\"Precision:\", precision_score(y_test, y_pred))\n",
        "    print(\"Recall   :\", recall_score(y_test, y_pred))\n",
        "    print(\"F1 Score :\", f1_score(y_test, y_pred))\n",
        "    print(\"ROC AUC  :\", roc_auc_score(y_test, y_proba))\n",
        "    print(\"\\nClassification Report:\")\n",
        "    print(classification_report(y_test, y_pred))\n",
        "\n",
        "    # Prediction breakdown\n",
        "    print(\"\\n Prediction breakdown (first 20 samples):\")\n",
        "    results_df = pd.DataFrame({\n",
        "        'Actual Label': y_test.values,\n",
        "        'Predicted Label': y_pred,\n",
        "        'Cancer Prob (class=1)': y_proba\n",
        "    })\n",
        "    print(results_df.head(20))\n",
        "\n",
        "\n",
        "# 1. XGBoost with Lasso-selected features\n",
        "xgb_lasso = XGBClassifier(n_estimators=100, learning_rate=0.1, max_depth=3,\n",
        "                          random_state=42, use_label_encoder=False, eval_metric='logloss')\n",
        "xgb_lasso.fit(X_train_lasso, y_train)\n",
        "evaluate_model(xgb_lasso, X_test_lasso, y_test, name=\"XGBoost (Lasso Features)\")\n",
        "\n",
        "\n",
        "# 2. XGBoost with RFE-selected features\n",
        "xgb_rfe = XGBClassifier(n_estimators=100, learning_rate=0.1, max_depth=3,\n",
        "                        random_state=42, use_label_encoder=False, eval_metric='logloss')\n",
        "xgb_rfe.fit(X_train_rfe, y_train)\n",
        "evaluate_model(xgb_rfe, X_test_rfe, y_test, name=\"XGBoost (RFE Features)\")"
      ],
      "metadata": {
        "id": "VjPAPU8SbpqE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. MLP"
      ],
      "metadata": {
        "id": "sJq820TJb1fH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, classification_report\n",
        "import pandas as pd\n",
        "\n",
        "# Evaluation function (same as before)\n",
        "def evaluate_model(model, X_test, y_test, name=\"Model\"):\n",
        "    y_pred = model.predict(X_test)\n",
        "    y_proba = model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "    print(f\"\\n Evaluation Report for {name}\")\n",
        "    print(\"Accuracy :\", accuracy_score(y_test, y_pred))\n",
        "    print(\"Precision:\", precision_score(y_test, y_pred))\n",
        "    print(\"Recall   :\", recall_score(y_test, y_pred))\n",
        "    print(\"F1 Score :\", f1_score(y_test, y_pred))\n",
        "    print(\"ROC AUC  :\", roc_auc_score(y_test, y_proba))\n",
        "    print(\"\\nClassification Report:\")\n",
        "    print(classification_report(y_test, y_pred))\n",
        "\n",
        "    # Sample-wise prediction breakdown\n",
        "    print(\"\\n Prediction breakdown (first 20 samples):\")\n",
        "    results_df = pd.DataFrame({\n",
        "        'Actual Label': y_test.values,\n",
        "        'Predicted Label': y_pred,\n",
        "        'Cancer Probability (class=1)': y_proba\n",
        "    })\n",
        "    print(results_df.head(20))\n",
        "\n",
        "\n",
        "# Train MLP on Lasso-selected features\n",
        "mlp_lasso = MLPClassifier(hidden_layer_sizes=(100,), activation='relu', solver='adam',\n",
        "                          max_iter=500, random_state=42)\n",
        "mlp_lasso.fit(X_train_lasso, y_train)\n",
        "evaluate_model(mlp_lasso, X_test_lasso, y_test, name=\"MLP Classifier (Lasso Features)\")\n",
        "\n",
        "\n",
        "# Train MLP on RFE-selected features\n",
        "mlp_rfe = MLPClassifier(hidden_layer_sizes=(100,), activation='relu', solver='adam',\n",
        "                        max_iter=500, random_state=42)\n",
        "mlp_rfe.fit(X_train_rfe, y_train)\n",
        "evaluate_model(mlp_rfe, X_test_rfe, y_test, name=\"MLP Classifier (RFE Features)\")"
      ],
      "metadata": {
        "id": "dpKSJFtCbdtj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# EXPLAINABLE ML"
      ],
      "metadata": {
        "id": "ISj1elW7cYW7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. SHAPLEY"
      ],
      "metadata": {
        "id": "1cbQuaOnvmpk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1(A). SHAP - Logistic Regression x LASSO50"
      ],
      "metadata": {
        "id": "_jGFj1spcd5c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- SHAP for Logistic Regression (LASSO) ---\n",
        "import shap\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# small background to estimate the expectation (keeps it fast & avoids leakage)\n",
        "bg_lasso = shap.sample(X_train_lasso, 300, random_state=42)\n",
        "\n",
        "# LinearExplainer is the correct choice for (penalized) linear models\n",
        "expl_lr_lasso = shap.LinearExplainer(lr_lasso, bg_lasso)\n",
        "\n",
        "# SHAP values on the held-out TEST\n",
        "sv_lasso = expl_lr_lasso.shap_values(X_test_lasso)\n",
        "\n",
        "# If SHAP returns a list (some versions do), take the positive class (index 1)\n",
        "if isinstance(sv_lasso, list):\n",
        "    sv_lasso = sv_lasso[1]\n",
        "\n",
        "# Plots: global importance (bar) + beeswarm\n",
        "shap.summary_plot(sv_lasso, X_test_lasso, plot_type=\"bar\", show=True)\n",
        "shap.summary_plot(sv_lasso, X_test_lasso, show=True)"
      ],
      "metadata": {
        "id": "_WynQU8zcKNT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1(B). SHAP - Logistic Regression X RFE50"
      ],
      "metadata": {
        "id": "CQRnJj8ugLPJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- SHAP for Logistic Regression (RFE) ---\n",
        "bg_rfe = shap.sample(X_train_rfe, 300, random_state=42)\n",
        "\n",
        "expl_lr_rfe = shap.LinearExplainer(lr_rfe, bg_rfe)\n",
        "sv_rfe = expl_lr_rfe.shap_values(X_test_rfe)\n",
        "\n",
        "if isinstance(sv_rfe, list):\n",
        "    sv_rfe = sv_rfe[1]\n",
        "\n",
        "shap.summary_plot(sv_rfe, X_test_rfe, plot_type=\"bar\", show=True)\n",
        "shap.summary_plot(sv_rfe, X_test_rfe, show=True)"
      ],
      "metadata": {
        "id": "wJbCj1fKfton"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2(A). SHAP - SVM X LASSO50"
      ],
      "metadata": {
        "id": "a1NvIXCEhEI4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- SHAP for SVM (binary) â€” LASSO50 ---\n",
        "import shap, numpy as np, pandas as pd\n",
        "\n",
        "np.random.seed(42)  # for reproducibility of kmeans sampling\n",
        "\n",
        "cols_lasso = X_train_lasso.columns\n",
        "\n",
        "# summarize background to speed up Kernel SHAP\n",
        "bg_lasso = shap.kmeans(X_train_lasso[cols_lasso], 100)   # <-- no random_state here\n",
        "\n",
        "# wrapper: restore feature names before calling the model\n",
        "def f_svm_lasso(X):\n",
        "    X_df = pd.DataFrame(X, columns=cols_lasso)\n",
        "    return svm_lasso.predict_proba(X_df)[:, 1]\n",
        "\n",
        "expl_svm_lasso = shap.KernelExplainer(f_svm_lasso, bg_lasso, link=\"logit\")\n",
        "\n",
        "# optional: subsample TEST for speed\n",
        "X_test_lasso_shap = X_test_lasso[cols_lasso].sample(800, random_state=42)\n",
        "\n",
        "sv_lasso = expl_svm_lasso.shap_values(X_test_lasso_shap, nsamples=\"auto\")\n",
        "\n",
        "shap.summary_plot(sv_lasso, X_test_lasso_shap, plot_type=\"bar\", show=True)\n",
        "shap.summary_plot(sv_lasso, X_test_lasso_shap, show=True)"
      ],
      "metadata": {
        "id": "cRaJCzokgYh3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2(B). SHAP - SVM X RFE50"
      ],
      "metadata": {
        "id": "HPeBrBHHmwaX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- SHAP for SVM (binary) â€” RFE50 ---\n",
        "np.random.seed(42)\n",
        "\n",
        "cols_rfe = X_train_rfe.columns\n",
        "bg_rfe = shap.kmeans(X_train_rfe[cols_rfe], 100)         # <-- no random_state\n",
        "\n",
        "def f_svm_rfe(X):\n",
        "    X_df = pd.DataFrame(X, columns=cols_rfe)\n",
        "    return svm_rfe.predict_proba(X_df)[:, 1]\n",
        "\n",
        "expl_svm_rfe = shap.KernelExplainer(f_svm_rfe, bg_rfe, link=\"logit\")\n",
        "\n",
        "X_test_rfe_shap = X_test_rfe[cols_rfe].sample(800, random_state=42)\n",
        "\n",
        "sv_rfe = expl_svm_rfe.shap_values(X_test_rfe_shap, nsamples=\"auto\")\n",
        "\n",
        "shap.summary_plot(sv_rfe, X_test_rfe_shap, plot_type=\"bar\", show=True)\n",
        "shap.summary_plot(sv_rfe, X_test_rfe_shap, show=True)"
      ],
      "metadata": {
        "id": "QHfOinluhau3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3(A). SHAP - RF X LASSO50"
      ],
      "metadata": {
        "id": "YRA0h8mcp0wp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import shap\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Initialize explainer\n",
        "explainer_rf_lasso = shap.TreeExplainer(rf_lasso)\n",
        "\n",
        "# Compute SHAP values (should be a 2D numpy array of shape [n_samples, n_features])\n",
        "shap_values_lasso = explainer_rf_lasso.shap_values(X_test_lasso)\n",
        "\n",
        "# If it returns a list, extract class 1 values (positive class)\n",
        "if isinstance(shap_values_lasso, list):\n",
        "    shap_values_lasso = shap_values_lasso[1]\n",
        "\n",
        "# Plot SHAP summary\n",
        "shap.summary_plot(shap_values_lasso, X_test_lasso, plot_type=\"bar\")\n",
        "shap.summary_plot(shap_values_lasso, X_test_lasso)"
      ],
      "metadata": {
        "id": "ghr6T5XPmt7Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3(B). SHAP - RF X RFE50"
      ],
      "metadata": {
        "id": "V751WlfEtcUx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize SHAP explainer for RFE-selected Random Forest model\n",
        "explainer_rf_rfe = shap.TreeExplainer(rf_rfe)\n",
        "\n",
        "# Compute SHAP values for RFE test set\n",
        "shap_values_rfe = explainer_rf_rfe.shap_values(X_test_rfe)\n",
        "\n",
        "# If binary classification, extract class 1 SHAP values\n",
        "if isinstance(shap_values_rfe, list):\n",
        "    shap_values_rfe = shap_values_rfe[1]\n",
        "\n",
        "# Plot SHAP summary (bar and beeswarm)\n",
        "shap.summary_plot(shap_values_rfe, X_test_rfe, plot_type=\"bar\")\n",
        "shap.summary_plot(shap_values_rfe, X_test_rfe)"
      ],
      "metadata": {
        "id": "vBNELyvCp-8e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4(A). SHAP - XGBoost X LASSO50"
      ],
      "metadata": {
        "id": "qCV0Xg5ztsKh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ========== XGBoost with Lasso Features ==========\n",
        "# Initialize SHAP explainer\n",
        "explainer_xgb_lasso = shap.TreeExplainer(xgb_lasso)\n",
        "\n",
        "# Compute SHAP values\n",
        "shap_values_lasso = explainer_xgb_lasso.shap_values(X_test_lasso)\n",
        "\n",
        "# If binary classification, extract class 1 SHAP values\n",
        "if isinstance(shap_values_lasso, list):\n",
        "    shap_values_lasso = shap_values_lasso[1]\n",
        "\n",
        "# Plot SHAP summary (bar and beeswarm)\n",
        "shap.summary_plot(shap_values_lasso, X_test_lasso, plot_type=\"bar\")\n",
        "shap.summary_plot(shap_values_lasso, X_test_lasso)"
      ],
      "metadata": {
        "id": "1BwmcJLTtkjn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4(B). SHAP - XGBoost X RFE50"
      ],
      "metadata": {
        "id": "gFty_ovNt1RN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize SHAP explainer\n",
        "explainer_xgb_rfe = shap.TreeExplainer(xgb_rfe)\n",
        "\n",
        "# Compute SHAP values\n",
        "shap_values_rfe = explainer_xgb_rfe.shap_values(X_test_rfe)\n",
        "\n",
        "# If binary classification, extract class 1 SHAP values\n",
        "if isinstance(shap_values_rfe, list):\n",
        "    shap_values_rfe = shap_values_rfe[1]\n",
        "\n",
        "# Plot SHAP summary (bar and beeswarm)\n",
        "shap.summary_plot(shap_values_rfe, X_test_rfe, plot_type=\"bar\")\n",
        "shap.summary_plot(shap_values_rfe, X_test_rfe)"
      ],
      "metadata": {
        "id": "spKhhyKBtzXF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5(A). SHAP - MLP X LASSO50"
      ],
      "metadata": {
        "id": "K1nioFjtupjP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- SHAP for MLP (binary) â€” LASSO50 ---\n",
        "import shap, numpy as np, pandas as pd\n",
        "\n",
        "cols_lasso = X_train_lasso.columns\n",
        "\n",
        "# compact background to speed up Kernel SHAP\n",
        "bg_lasso = shap.kmeans(X_train_lasso[cols_lasso], 100)  # or: shap.sample(..., 300)\n",
        "\n",
        "# wrapper that restores feature names and returns P(class=1)\n",
        "def f_mlp_lasso(X):\n",
        "    X_df = pd.DataFrame(X, columns=cols_lasso)\n",
        "    return mlp_lasso.predict_proba(X_df)[:, 1]\n",
        "\n",
        "# model-agnostic explainer; use logit link so additivity is on log-odds\n",
        "expl_mlp_lasso = shap.KernelExplainer(f_mlp_lasso, bg_lasso, link=\"logit\")\n",
        "\n",
        "# optional: subsample TEST to keep things snappy\n",
        "X_test_lasso_shap = X_test_lasso[cols_lasso].sample(800, random_state=42)\n",
        "\n",
        "# SHAP values\n",
        "sv_lasso = expl_mlp_lasso.shap_values(X_test_lasso_shap, nsamples=\"auto\")\n",
        "\n",
        "# plots\n",
        "shap.summary_plot(sv_lasso, X_test_lasso_shap, plot_type=\"bar\", show=True)\n",
        "shap.summary_plot(sv_lasso, X_test_lasso_shap, show=True)"
      ],
      "metadata": {
        "id": "Y0lztu92t8wP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5(B). SHAP - MLP X RFE50"
      ],
      "metadata": {
        "id": "V9nvZQQ6uxRs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- SHAP for MLP (binary) â€” RFE50 ---\n",
        "cols_rfe = X_train_rfe.columns\n",
        "bg_rfe = shap.kmeans(X_train_rfe[cols_rfe], 100)\n",
        "\n",
        "def f_mlp_rfe(X):\n",
        "    X_df = pd.DataFrame(X, columns=cols_rfe)\n",
        "    return mlp_rfe.predict_proba(X_df)[:, 1]\n",
        "\n",
        "expl_mlp_rfe = shap.KernelExplainer(f_mlp_rfe, bg_rfe, link=\"logit\")\n",
        "\n",
        "X_test_rfe_shap = X_test_rfe[cols_rfe].sample(800, random_state=42)\n",
        "sv_rfe = expl_mlp_rfe.shap_values(X_test_rfe_shap, nsamples=\"auto\")\n",
        "\n",
        "shap.summary_plot(sv_rfe, X_test_rfe_shap, plot_type=\"bar\", show=True)\n",
        "shap.summary_plot(sv_rfe, X_test_rfe_shap, show=True)"
      ],
      "metadata": {
        "id": "ZGrblx72unPI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. PDP + ICE"
      ],
      "metadata": {
        "id": "CnJMlOMsvu8G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==== PDP + ICE for all models (Lasso & RFE feature sets) ====\n",
        "from sklearn.inspection import PartialDependenceDisplay, permutation_importance\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# --- helpers --------------------------------------------------\n",
        "def _unwrap(est):\n",
        "    return est.named_steps[list(est.named_steps)[-1]] if hasattr(est, \"named_steps\") else est\n",
        "\n",
        "def _resp_method(est):\n",
        "    return \"predict_proba\" if hasattr(est, \"predict_proba\") else \"decision_function\"\n",
        "\n",
        "def _rank_features(estimator, X_ref, y_ref=None, k=8, fallback_names=None, use_perm=False):\n",
        "    \"\"\"Rank features by model-native importance/coef; optionally fallback to permutation importance.\"\"\"\n",
        "    fin = _unwrap(estimator)\n",
        "    names = list(X_ref.columns) if hasattr(X_ref, \"columns\") else [f\"f{i}\" for i in range(X_ref.shape[1])]\n",
        "\n",
        "    if hasattr(fin, \"feature_importances_\"):\n",
        "        w = np.asarray(fin.feature_importances_)\n",
        "    elif hasattr(fin, \"coef_\"):\n",
        "        w = np.mean(np.abs(np.asarray(fin.coef_)), axis=0)  # binary/multiclass\n",
        "    elif use_perm and (y_ref is not None):\n",
        "        # permutation importance on the provided reference set (usually X_test_* for speed)\n",
        "        pi = permutation_importance(estimator, X_ref, y_ref, n_repeats=5, random_state=42, scoring=\"roc_auc\")\n",
        "        w = pi.importances_mean\n",
        "    else:\n",
        "        # just take the first k if nothing else available\n",
        "        return names[:k]\n",
        "\n",
        "    order = np.argsort(w)[::-1][:k]\n",
        "    return [names[i] for i in order]\n",
        "\n",
        "def plot_pdp_block(model, X_ref, label, k=8, target_idx=1, grid=50, use_perm=False, y_ref=None, n_cols=2):\n",
        "    feats = _rank_features(model, X_ref, y_ref=y_ref, k=k, use_perm=use_perm)\n",
        "\n",
        "    disp = PartialDependenceDisplay.from_estimator(\n",
        "        model,\n",
        "        X_ref,\n",
        "        features=feats,\n",
        "        kind=\"both\",\n",
        "        grid_resolution=grid,\n",
        "        target=target_idx,\n",
        "        response_method=_resp_method(_unwrap(model)),\n",
        "        n_jobs=-1\n",
        "    )\n",
        "    # Adjust layout: n_cols controls how many plots per row\n",
        "    n_rows = int(np.ceil(len(feats) / n_cols))\n",
        "    fig = plt.gcf()\n",
        "    fig.set_size_inches(5 * n_cols, 3 * n_rows)\n",
        "    fig.suptitle(f\"{label} â€” PDP + ICE (top {len(feats)} features)\", y=1.02, fontsize=12)\n",
        "    plt.tight_layout(rect=[0, 0, 1, 0.97])\n",
        "    plt.show()\n",
        "\n",
        "    return feats"
      ],
      "metadata": {
        "id": "gCy__zUevf94"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. PDP - Logistic Regression"
      ],
      "metadata": {
        "id": "iE0XgqE9wmmm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "topk = 10\n",
        "\n",
        "# --- Logistic Regression ---\n",
        "lr_lasso_feats = plot_pdp_block(lr_lasso, X_train_lasso, \"Logistic Regression (Lasso)\", k=topk, target_idx=1)\n",
        "lr_rfe_feats   = plot_pdp_block(lr_rfe,   X_train_rfe,   \"Logistic Regression (RFE)\",   k=topk, target_idx=1)"
      ],
      "metadata": {
        "id": "h47huyi4wjGR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. PDP - SVM"
      ],
      "metadata": {
        "id": "PlyTpq6Jw2PL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- SVM (you trained with probability=True) ---\n",
        "svm_lasso_feats = plot_pdp_block(svm_lasso, X_train_lasso, \"SVM (Lasso)\", k=topk, target_idx=1)\n",
        "svm_rfe_feats   = plot_pdp_block(svm_rfe,   X_train_rfe,   \"SVM (RFE)\",   k=topk, target_idx=1)"
      ],
      "metadata": {
        "id": "tb8pRP1IwsrY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. PDP - Random Forest"
      ],
      "metadata": {
        "id": "oZwqQOoOxBI_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Random Forest ---\n",
        "rf_lasso_feats = plot_pdp_block(rf_lasso, X_train_lasso, \"Random Forest (Lasso)\", k=topk, target_idx=1)\n",
        "rf_rfe_feats   = plot_pdp_block(rf_rfe,   X_train_rfe,   \"Random Forest (RFE)\",   k=topk, target_idx=1)"
      ],
      "metadata": {
        "id": "doA5Z1rjw_Lk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. PDP - XGBoost"
      ],
      "metadata": {
        "id": "4PMDiAdVxPfI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- XGBoost ---\n",
        "xgb_lasso_feats = plot_pdp_block(xgb_lasso, X_train_lasso, \"XGBoost (Lasso)\", k=topk, target_idx=1)\n",
        "xgb_rfe_feats   = plot_pdp_block(xgb_rfe,   X_train_rfe,   \"XGBoost (RFE)\",   k=topk, target_idx=1)"
      ],
      "metadata": {
        "id": "ZtBxUa0mxM5U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. PDP - MLP"
      ],
      "metadata": {
        "id": "Jwfoy-aMxcHE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mlp_lasso_feats = plot_pdp_block(\n",
        "    mlp_lasso, X_test_lasso, \"MLP (Lasso)\",\n",
        "    k=topk, target_idx=1, use_perm=True, y_ref=y_test, n_cols=3\n",
        ")\n",
        "mlp_rfe_feats = plot_pdp_block(\n",
        "    mlp_rfe, X_test_rfe, \"MLP (RFE)\",\n",
        "    k=topk, target_idx=1, use_perm=True, y_ref=y_test, n_cols=3\n",
        ")"
      ],
      "metadata": {
        "id": "nQtJAoLuxZcQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PAM 50 subtype classification (5 Class)"
      ],
      "metadata": {
        "id": "0bSbd2Woxuh0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Meta-Data"
      ],
      "metadata": {
        "id": "_BHTVsN1yDkA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "scanb_xlsx_path = \"/content/drive/My Drive/Thesis2/subtype.xlsx\"\n",
        "\n",
        "# peek sheets so we know which one to read\n",
        "xlsx_handle = pd.ExcelFile(scanb_xlsx_path)\n",
        "print(\"Sheets:\", xlsx_handle.sheet_names)"
      ],
      "metadata": {
        "id": "hVZSVxPpxoHE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pick the correct sheet name from the print above\n",
        "scanb_sheet_name = xlsx_handle.sheet_names[0]   # <-- or e.g., \"Merged\"\n",
        "\n",
        "# read; dtype=None lets pandas infer types, keep_default_na=True to parse blanks as NaN\n",
        "scanb_meta_raw = pd.read_excel(scanb_xlsx_path, sheet_name=scanb_sheet_name)\n",
        "\n",
        "# strip whitespace from column names\n",
        "scanb_meta_raw.columns = scanb_meta_raw.columns.astype(str).str.strip()\n",
        "\n",
        "print(\"Meta shape:\", scanb_meta_raw.shape)\n",
        "scanb_meta_raw.head(3)"
      ],
      "metadata": {
        "id": "KRyRiM9NyGgk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for col in id_candidates:\n",
        "    print(col, list(map(str, scanb_meta_raw[col].dropna().astype(str).head(10))))"
      ],
      "metadata": {
        "id": "ok18gwMryKVQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Inspect the ORIGINAL indices (not expr_by_sample_df)\n",
        "print(\"X_scaled_df shape:\", X_scaled_df.shape)\n",
        "print(\"First 10 X_scaled_df indices:\", list(map(str, X_scaled_df.index[:10])))\n",
        "\n",
        "# If you still have `combined_df`, print that too (it should match X_scaled_df.index)\n",
        "if 'combined_df' in globals():\n",
        "    print(\"First 10 combined_df indices:\", list(map(str, combined_df.index[:10])))"
      ],
      "metadata": {
        "id": "YTFMb80AyN5h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# extract the core S####### id from your *row index*\n",
        "core_series = extract_core_sid(X_scaled_df.index)\n",
        "print(\"preview core IDs:\", core_series.head(5).tolist())\n",
        "\n",
        "expr_core_df = X_scaled_df.copy()\n",
        "expr_core_df[\"__KEY__\"] = core_series.values   # << critical: use .values (no alignment)\n",
        "expr_core_df = (\n",
        "    expr_core_df\n",
        "      .dropna(subset=[\"__KEY__\"])\n",
        "      .set_index(\"__KEY__\")\n",
        "      .groupby(level=0).median()               # collapse multiple libs per sample\n",
        ")\n",
        "\n",
        "print(\"expr_core_df shape:\", expr_core_df.shape)\n",
        "print(\"first 5 core IDs:\", expr_core_df.index[:5].tolist())"
      ],
      "metadata": {
        "id": "WohvFxztyfzA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- extract core sample IDs from the *row index* and collapse replicates ---\n",
        "\n",
        "# 1) Get the core ID for each row (library); this returns an Index in our pipeline\n",
        "core_idx = extract_core_sid(X_scaled_df.index)          # pd.Index (or Series)\n",
        "\n",
        "# Preview a few IDs (Index doesn't have .head(), so slice instead)\n",
        "print(\"preview core IDs:\", list(map(str, core_idx[:5])))\n",
        "\n",
        "# 2) Attach the core ID as a column and collapse multiple libraries per sample by median\n",
        "expr_core_df = X_scaled_df.copy()\n",
        "expr_core_df[\"__KEY__\"] = pd.Index(core_idx).to_numpy()  # ensure 1-D array, no alignment issues\n",
        "expr_core_df = (\n",
        "    expr_core_df\n",
        "      .dropna(subset=[\"__KEY__\"])\n",
        "      .set_index(\"__KEY__\")\n",
        "      .groupby(level=0).median()                         # collapse replicates\n",
        ")\n",
        "\n",
        "print(\"expr_core_df shape:\", expr_core_df.shape)\n",
        "print(\"first 5 core IDs:\", list(map(str, expr_core_df.index[:5])))"
      ],
      "metadata": {
        "id": "l5c89rz67jEb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "id_candidates = [c for c in [\"Sample\",\"RNA\",\"Case\",\"Patient\"] if c in scanb_meta_raw.columns]\n",
        "overlaps = {}\n",
        "for col in id_candidates:\n",
        "    meta_core = extract_core_sid(scanb_meta_raw[col])\n",
        "    overlaps[col] = len(set(meta_core.dropna()) & set(expr_core_df.index))\n",
        "    print(col, \"overlap:\", overlaps[col])\n",
        "\n",
        "best_col = max(overlaps, key=overlaps.get)\n",
        "print(\"Using metadata column:\", best_col, \"with overlap:\", overlaps[best_col])"
      ],
      "metadata": {
        "id": "l9J8ij812og8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pam50_label_col = \"NCN.PAM50\""
      ],
      "metadata": {
        "id": "0t6cEpWQChjJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "meta_core_df = (\n",
        "    scanb_meta_raw\n",
        "      .dropna(subset=[best_col, pam50_label_col])\n",
        "      .assign(__KEY__=extract_core_sid(scanb_meta_raw[best_col]).values)  # use .values\n",
        "      .dropna(subset=[\"__KEY__\"])\n",
        "      .drop_duplicates(\"__KEY__\")\n",
        "      .set_index(\"__KEY__\")\n",
        ")\n",
        "\n",
        "common_ids = meta_core_df.index.intersection(expr_core_df.index)\n",
        "print(\"Common after core-ID normalization:\", len(common_ids))\n",
        "\n",
        "meta_aligned_df   = meta_core_df.loc[common_ids].copy()\n",
        "expr_by_sample_df = expr_core_df.loc[common_ids].copy()\n",
        "\n",
        "meta_aligned_df[[pam50_label_col, \"Training.set\"]].head()"
      ],
      "metadata": {
        "id": "bE9ZcfD3237k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# sanity: same samples and same order\n",
        "assert set(expr_by_sample_df.index) == set(meta_aligned_df.index)\n",
        "expr_by_sample_df = expr_by_sample_df.loc[meta_aligned_df.index]  # enforce same order\n",
        "\n",
        "print(\"Expr shape:\", expr_by_sample_df.shape)\n",
        "print(\"Meta shape:\", meta_aligned_df.shape)\n",
        "print(\"Label counts:\\n\", meta_aligned_df[pam50_label_col].value_counts())\n",
        "print(\"Train/Test:\\n\", meta_aligned_df[\"Training.set\"].value_counts())"
      ],
      "metadata": {
        "id": "6jBPDpIi26rb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CLASSIFICATION MODELS"
      ],
      "metadata": {
        "id": "Tnapm6gv3V3p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define the model:"
      ],
      "metadata": {
        "id": "UiKBx0qy3bAa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "def model_zoo(num_classes):\n",
        "    return {\n",
        "        \"LogReg\": Pipeline([(\"z\", StandardScaler()),\n",
        "                            (\"clf\", LogisticRegression(max_iter=5000,\n",
        "                                                       multi_class=\"multinomial\",\n",
        "                                                       class_weight=\"balanced\",\n",
        "                                                       random_state=42))]),\n",
        "        \"SVM\":    Pipeline([(\"z\", StandardScaler()),\n",
        "                            (\"clf\", SVC(kernel=\"rbf\",\n",
        "                                        probability=True,\n",
        "                                        class_weight=\"balanced\",\n",
        "                                        random_state=42))]),\n",
        "        \"RF\":     RandomForestClassifier(n_estimators=400,\n",
        "                                         class_weight=\"balanced\",\n",
        "                                         n_jobs=-1, random_state=42),\n",
        "        \"XGB\":    XGBClassifier(objective=\"multi:softprob\",\n",
        "                                num_class=len(class_names),\n",
        "                                n_estimators=500, learning_rate=0.1,\n",
        "                                max_depth=6, subsample=0.9, colsample_bytree=0.9,\n",
        "                                reg_lambda=1.0, n_jobs=-1, random_state=42,\n",
        "                                eval_metric=\"mlogloss\"),\n",
        "        \"MLP\":    Pipeline([(\"z\", StandardScaler()),\n",
        "                            (\"clf\", MLPClassifier(hidden_layer_sizes=(128,),\n",
        "                                                  activation=\"relu\",\n",
        "                                                  solver=\"adam\",\n",
        "                                                  max_iter=800,\n",
        "                                                  random_state=42))]),\n",
        "    }"
      ],
      "metadata": {
        "id": "dvAxO6k528yF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PAM50 feature matrices + targets + train/test"
      ],
      "metadata": {
        "id": "38H-KVXzFXyX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Build PAM50 feature matrices + targets + train/test ids ---\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from pathlib import Path\n",
        "\n",
        "# 0) assumes you already have:\n",
        "#    expr_by_sample_df  (rows = sample IDs, cols = genes)\n",
        "#    meta_aligned_df    (same index as expr_by_sample_df; has pam50 + Training.set)\n",
        "#    pam50_label_col    (e.g., \"NCN.PAM50\")\n",
        "\n",
        "# 1) Load/confirm 50-gene panels and subset expression\n",
        "def load_gene_list(csv_path, df):\n",
        "    try:\n",
        "        cols = pd.read_csv(csv_path, nrows=0).columns.tolist()\n",
        "    except Exception as e:\n",
        "        print(f\"Warning: could not read {csv_path}: {e}\")\n",
        "        cols = []\n",
        "    # keep only genes present in the data\n",
        "    return [c for c in cols if c in df.columns]\n",
        "\n",
        "lasso_csv_path = \"/content/drive/My Drive/Thesis2/Lasso_Selected_Genes.csv\"\n",
        "rfe_csv_path   = \"/content/drive/My Drive/Thesis2/RFE_Selected_Genes.csv\"\n",
        "\n",
        "# allow fallback if these were already defined upstream\n",
        "top_50_genes_lasso = globals().get(\"top_50_genes_lasso\", []) or load_gene_list(lasso_csv_path, expr_by_sample_df)\n",
        "top_50_genes_rfe   = globals().get(\"top_50_genes_rfe\",   []) or load_gene_list(rfe_csv_path,   expr_by_sample_df)\n",
        "\n",
        "print(\"LASSO50 present:\", len(top_50_genes_lasso))\n",
        "print(\"RFE50 present :\", len(top_50_genes_rfe))\n",
        "\n",
        "X_lasso50_full = expr_by_sample_df[top_50_genes_lasso].copy()\n",
        "X_rfe50_full   = expr_by_sample_df[top_50_genes_rfe].copy()\n",
        "\n",
        "# 2) Targets and fixed train/test split from metadata\n",
        "y_str = meta_aligned_df[pam50_label_col].astype(str).str.strip()\n",
        "le = LabelEncoder()\n",
        "y_enc = pd.Series(le.fit_transform(y_str), index=y_str.index)\n",
        "class_names = list(le.classes_)\n",
        "\n",
        "train_mask = meta_aligned_df[\"Training.set\"].astype(bool)\n",
        "train_ids = y_enc.index[train_mask]\n",
        "test_ids  = y_enc.index[~train_mask]\n",
        "\n",
        "print(\"Shapes â€” X_lasso50_full:\", X_lasso50_full.shape, \" X_rfe50_full:\", X_rfe50_full.shape)\n",
        "print(\"Classes:\", class_names)\n",
        "print(f\"Split: train={len(train_ids)}, test={len(test_ids)}\")"
      ],
      "metadata": {
        "id": "XLlpjFi1FKVX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluate"
      ],
      "metadata": {
        "id": "eKmXTThNFbzp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score\n",
        "import pandas as pd\n",
        "\n",
        "def train_eval_feature_set(X_full, name):\n",
        "    X_tr, X_te = X_full.loc[train_ids], X_full.loc[test_ids]\n",
        "    y_tr, y_te = y_enc.loc[train_ids], y_enc.loc[test_ids]\n",
        "\n",
        "    results = []\n",
        "    models = model_zoo(len(class_names))\n",
        "    for mname, model in models.items():\n",
        "        model.fit(X_tr, y_tr)\n",
        "        y_pred = model.predict(X_te)\n",
        "        acc = accuracy_score(y_te, y_pred)\n",
        "        f1m = f1_score(y_te, y_pred, average=\"macro\")\n",
        "        results.append((mname, acc, f1m))\n",
        "        print(f\"\\n=== {name} Â· {mname} ===\")\n",
        "        print(classification_report(y_te, y_pred, target_names=class_names, digits=3))\n",
        "        print(confusion_matrix(y_te, y_pred))\n",
        "    res = pd.DataFrame(results, columns=[\"Model\",\"Accuracy\",\"MacroF1\"]).set_index(\"Model\").sort_values(\"MacroF1\", ascending=False)\n",
        "    print(f\"\\n{name} summary:\\n\", res)\n",
        "    return res"
      ],
      "metadata": {
        "id": "vSLg3eoz3ft4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CLASSIFICATION MODELS"
      ],
      "metadata": {
        "id": "XFAMeHb5FsrU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. For LASSO50"
      ],
      "metadata": {
        "id": "E0zlo_1w3si3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lasso_summary = train_eval_feature_set(X_lasso50_full, \"LASSO50\")"
      ],
      "metadata": {
        "id": "oA-dNzHg3kok"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. For RFE50"
      ],
      "metadata": {
        "id": "FnFLM3_jFiN1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rfe_summary = train_eval_feature_set(X_rfe50_full, \"RFE50\")"
      ],
      "metadata": {
        "id": "cmne-PIF3yaM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1) combine into one tidy table\n",
        "comparison_df = (\n",
        "    pd.concat({'LASSO50': lasso_summary, 'RFE50': rfe_summary}, names=['FeatureSet'])\n",
        "      .reset_index()  # columns: FeatureSet, Model, Accuracy, MacroF1\n",
        ")\n",
        "comparison_df = comparison_df.sort_values(['MacroF1','Accuracy'], ascending=False)\n",
        "print(\"== Combined summary (sorted by MacroF1) ==\")\n",
        "display(comparison_df)\n",
        "\n",
        "# 2) bar chart of Macro-F1\n",
        "plt.figure(figsize=(8,4))\n",
        "for fs in ['LASSO50','RFE50']:\n",
        "    sub = comparison_df[comparison_df['FeatureSet']==fs]\n",
        "    plt.bar(sub['Model'] + \" (\"+fs+\")\", sub['MacroF1'])\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.ylabel(\"Macro-F1\")\n",
        "plt.title(\"Subtype classification: Macro-F1 by model & feature set\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# 3) pick best model name per feature set\n",
        "best_lasso_model = lasso_summary['MacroF1'].idxmax()\n",
        "best_rfe_model   = rfe_summary['MacroF1'].idxmax()\n",
        "print(\"Best LASSO50 model:\", best_lasso_model)\n",
        "print(\"Best RFE50 model  :\", best_rfe_model)"
      ],
      "metadata": {
        "id": "SxpheSAjGchB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## helper to refit + evaluate + plot confusion matrix"
      ],
      "metadata": {
        "id": "7IihtQxKF3db"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay, accuracy_score, f1_score\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def refit_and_eval(X_full, model_name, label_note):\n",
        "    # data split\n",
        "    X_tr, X_te = X_full.loc[train_ids], X_full.loc[test_ids]\n",
        "    y_tr, y_te = y_enc.loc[train_ids], y_enc.loc[test_ids]\n",
        "\n",
        "    # get a fresh instance of the chosen model\n",
        "    clf = model_zoo(len(class_names))[model_name]\n",
        "    clf.fit(X_tr, y_tr)\n",
        "\n",
        "    # predictions\n",
        "    y_pred = clf.predict(X_te)\n",
        "\n",
        "    # metrics\n",
        "    acc = accuracy_score(y_te, y_pred)\n",
        "    f1m = f1_score(y_te, y_pred, average=\"macro\")\n",
        "    print(f\"\\n== {label_note} Â· {model_name} ==\")\n",
        "    print(f\"Accuracy: {acc:.3f} | Macro-F1: {f1m:.3f}\\n\")\n",
        "    print(classification_report(y_te, y_pred, target_names=class_names, digits=3))\n",
        "\n",
        "    # confusion matrix\n",
        "    cm = confusion_matrix(y_te, y_pred, labels=range(len(class_names)))\n",
        "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_names)\n",
        "    fig, ax = plt.subplots(figsize=(6, 5))\n",
        "    disp.plot(ax=ax, xticks_rotation=45, colorbar=False)\n",
        "    plt.title(f\"{label_note} Â· {model_name}\")\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    return clf, y_pred"
      ],
      "metadata": {
        "id": "uM3AoJ-RFohb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Refit/evaluate the best LASSO50 model"
      ],
      "metadata": {
        "id": "9TQaq8UwF96M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_lasso_model  # should already be defined from the summary step\n",
        "clf_lasso_best, ypred_lasso = refit_and_eval(X_lasso50_full, best_lasso_model, \"LASSO50\")"
      ],
      "metadata": {
        "id": "JjSJdJjyF7T1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Refit/evaluate the best RFE50 model"
      ],
      "metadata": {
        "id": "KGzG6kHCGmDu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_rfe_model  # should already be defined from the summary step\n",
        "clf_rfe_best, ypred_rfe = refit_and_eval(X_rfe50_full, best_rfe_model, \"RFE50\")"
      ],
      "metadata": {
        "id": "pJcUr0spGBDd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Excluding â€œunclassifiedâ€"
      ],
      "metadata": {
        "id": "Q04m34w2GvRh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# which string is used for that class in your labels?\n",
        "uncl_token = \"unclassified\"\n",
        "\n",
        "# mask test set to drop \"unclassified\"\n",
        "test_labels_series = meta_aligned_df.loc[test_ids, pam50_label_col].astype(str).str.strip()\n",
        "keep_mask = test_labels_series.str.lower() != uncl_token\n",
        "\n",
        "X_te_clean = X_rfe50_full.loc[test_ids[keep_mask.values]]\n",
        "y_te_clean = y_enc.loc[test_ids[keep_mask.values]]\n",
        "\n",
        "# re-predict with your already-fitted champion (clf_rfe_best)\n",
        "y_pred_clean = clf_rfe_best.predict(X_te_clean)\n",
        "\n",
        "# restrict names/labels to the kept classes\n",
        "kept_class_names = [c for c in class_names if c.lower() != uncl_token]\n",
        "kept_label_ids   = [int(v) for v in le.transform(kept_class_names)]\n",
        "\n",
        "print(classification_report(y_te_clean, y_pred_clean, target_names=class_names, labels=kept_label_ids, digits=3))\n",
        "\n",
        "cm = confusion_matrix(y_te_clean, y_pred_clean, labels=kept_label_ids)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=kept_class_names)\n",
        "fig, ax = plt.subplots(figsize=(6,5))\n",
        "disp.plot(ax=ax, xticks_rotation=45, colorbar=False)\n",
        "plt.title(\"RFE50 Â· XGB (unclassified removed)\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "AK_xrPoGGsS8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# EXPLAINABLE ML"
      ],
      "metadata": {
        "id": "F0y078KYG0cT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# interpret RFE50 first\n",
        "X_feat = X_rfe50_full\n",
        "X_tr, X_te = X_feat.loc[train_ids], X_feat.loc[test_ids]\n",
        "y_tr, y_te = y_enc.loc[train_ids], y_enc.loc[test_ids]\n",
        "\n",
        "models_rfe = model_zoo(num_classes=len(class_names))  # from earlier\n",
        "for name in models_rfe:\n",
        "    models_rfe[name].fit(X_tr, y_tr)\n",
        "\n",
        "list(models_rfe.keys())"
      ],
      "metadata": {
        "id": "HRLMyQ9PGyh9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5 Models are fitted on RFE50"
      ],
      "metadata": {
        "id": "l_EzDSf7G7Ta"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_tr_rfe = X_rfe50_full.loc[train_ids]\n",
        "X_te_rfe = X_rfe50_full.loc[test_ids]\n",
        "y_tr     = y_enc.loc[train_ids]\n",
        "\n",
        "models_rfe = model_zoo(num_classes=len(class_names))\n",
        "for name, m in models_rfe.items():\n",
        "    m.fit(X_tr_rfe, y_tr)\n",
        "\n",
        "# pick which class to visualize\n",
        "class_to_plot = \"LumA\"  # change to \"LumB\", \"Basal\", \"HER2\", \"Normal\"\n",
        "class_idx = class_names.index(class_to_plot)"
      ],
      "metadata": {
        "id": "znQPu41ZG5Bf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SHAP for tree models + RFE (Random Forest, XGBoost)"
      ],
      "metadata": {
        "id": "NdCgrMEXHLb-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ---- RF (RFE50) ----\n",
        "explainer_rf_rfe = shap.TreeExplainer(models_rfe[\"RF\"])\n",
        "shap_vals_rf_rfe = explainer_rf_rfe.shap_values(X_te_rfe)\n",
        "if isinstance(shap_vals_rf_rfe, list):\n",
        "    shap_vals_rf_rfe = shap_vals_rf_rfe[class_idx]\n",
        "\n",
        "shap.summary_plot(shap_vals_rf_rfe, X_te_rfe, plot_type=\"bar\", show=True)\n",
        "shap.summary_plot(shap_vals_rf_rfe, X_te_rfe, show=True)"
      ],
      "metadata": {
        "id": "-Q4HN0rhHItJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---- XGB (RFE50) ----\n",
        "explainer_xgb_rfe = shap.TreeExplainer(models_rfe[\"XGB\"])\n",
        "shap_vals_xgb_rfe = explainer_xgb_rfe.shap_values(X_te_rfe)\n",
        "if isinstance(shap_vals_xgb_rfe, list):\n",
        "    shap_vals_xgb_rfe = shap_vals_xgb_rfe[class_idx]\n",
        "\n",
        "shap.summary_plot(shap_vals_xgb_rfe, X_te_rfe, plot_type=\"bar\", show=True)\n",
        "shap.summary_plot(shap_vals_xgb_rfe, X_te_rfe, show=True)"
      ],
      "metadata": {
        "id": "WG7Q3dchHVQd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "rng = np.random.default_rng(42)\n",
        "bg_idx   = rng.choice(len(X_tr_rfe), size=min(200, len(X_tr_rfe)), replace=False)\n",
        "eval_idx = rng.choice(len(X_te_rfe), size=min(600, len(X_te_rfe)), replace=False)\n",
        "X_bg     = X_tr_rfe.iloc[bg_idx]\n",
        "X_eval   = X_te_rfe.iloc[eval_idx]\n",
        "\n",
        "# ---- Logistic Regression (RFE50) ----\n",
        "expl_lr = shap.KernelExplainer(models_rfe[\"LogReg\"].predict_proba, X_bg)\n",
        "shap_vals_lr = expl_lr.shap_values(X_eval)            # list per class\n",
        "shap.summary_plot(shap_vals_lr[class_idx], X_eval, plot_type=\"bar\", show=True)\n",
        "shap.summary_plot(shap_vals_lr[class_idx], X_eval, show=True)\n",
        "\n",
        "# ---- SVM (RFE50) ----\n",
        "expl_svm = shap.KernelExplainer(models_rfe[\"SVM\"].predict_proba, X_bg)\n",
        "shap_vals_svm = expl_svm.shap_values(X_eval)\n",
        "shap.summary_plot(shap_vals_svm[class_idx], X_eval, plot_type=\"bar\", show=True)\n",
        "shap.summary_plot(shap_vals_svm[class_idx], X_eval, show=True)\n",
        "\n",
        "# ---- MLP (RFE50) ----\n",
        "expl_mlp = shap.KernelExplainer(models_rfe[\"MLP\"].predict_proba, X_bg)\n",
        "shap_vals_mlp = expl_mlp.shap_values(X_eval)\n",
        "shap.summary_plot(shap_vals_mlp[class_idx], X_eval, plot_type=\"bar\", show=True)\n",
        "shap.summary_plot(shap_vals_mlp[class_idx], X_eval, show=True)"
      ],
      "metadata": {
        "id": "pozi3MU9L_x6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SHAP for tree models + LASSO (Random Forest, XGBoost)"
      ],
      "metadata": {
        "id": "jw1hTmQCMH6s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Data splits\n",
        "X_tr_lasso = X_lasso50_full.loc[train_ids]\n",
        "X_te_lasso = X_lasso50_full.loc[test_ids]\n",
        "y_tr       = y_enc.loc[train_ids]\n",
        "\n",
        "# Fit only the two tree models (reuse your model_zoo for identical settings)\n",
        "rf_lasso  = model_zoo(len(class_names))[\"RF\"]\n",
        "xgb_lasso = model_zoo(len(class_names))[\"XGB\"]\n",
        "\n",
        "rf_lasso.fit(X_tr_lasso, y_tr)\n",
        "xgb_lasso.fit(X_tr_lasso, y_tr)\n",
        "\n",
        "# Choose which subtype to plot (change as you like)\n",
        "class_to_plot = \"LumA\"       # e.g., \"LumB\", \"Basal\", \"HER2\", \"Normal\"\n",
        "class_idx = class_names.index(class_to_plot)\n",
        "print(\"Plotting class:\", class_to_plot, \"-> index\", class_idx)"
      ],
      "metadata": {
        "id": "TvFWLaMxL9Vk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Random Forest (LASSO50) ---\n",
        "explainer_rf_lasso = shap.TreeExplainer(rf_lasso)\n",
        "sv_rf_lasso = explainer_rf_lasso.shap_values(X_te_lasso)\n",
        "if isinstance(sv_rf_lasso, list):   # multiclass -> list per class\n",
        "    sv_rf_lasso = sv_rf_lasso[class_idx]\n",
        "\n",
        "shap.summary_plot(sv_rf_lasso, X_te_lasso, plot_type=\"bar\", show=True)\n",
        "shap.summary_plot(sv_rf_lasso, X_te_lasso, show=True)"
      ],
      "metadata": {
        "id": "--epywIZMKF7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- XGBoost (LASSO50) ---\n",
        "explainer_xgb_lasso = shap.TreeExplainer(xgb_lasso)\n",
        "sv_xgb_lasso = explainer_xgb_lasso.shap_values(X_te_lasso)\n",
        "if isinstance(sv_xgb_lasso, list):\n",
        "    sv_xgb_lasso = sv_xgb_lasso[class_idx]\n",
        "\n",
        "shap.summary_plot(sv_xgb_lasso, X_te_lasso, plot_type=\"bar\", show=True)\n",
        "shap.summary_plot(sv_xgb_lasso, X_te_lasso, show=True)"
      ],
      "metadata": {
        "id": "9xafZPvcMNRH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. PDP"
      ],
      "metadata": {
        "id": "FwLPJx7tWV06"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Data splits\n",
        "X_tr_rfe, X_te_rfe = X_rfe50_full.loc[train_ids],  X_rfe50_full.loc[test_ids]\n",
        "X_tr_las, X_te_las = X_lasso50_full.loc[train_ids], X_lasso50_full.loc[test_ids]\n",
        "y_tr, y_te = y_enc.loc[train_ids], y_enc.loc[test_ids]\n",
        "\n",
        "# Fresh model sets\n",
        "models_rfe   = model_zoo(num_classes=len(class_names))\n",
        "models_lasso = model_zoo(num_classes=len(class_names))\n",
        "\n",
        "for m in models_rfe.values():   m.fit(X_tr_rfe, y_tr)\n",
        "for m in models_lasso.values(): m.fit(X_tr_las, y_tr)\n",
        "\n",
        "list(models_rfe.keys())  # ['LogReg','SVM','RF','XGB','MLP']"
      ],
      "metadata": {
        "id": "brmDaBIgV9mQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LUMA"
      ],
      "metadata": {
        "id": "kvZleSzuYMmo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# choose the subtype to visualize on the y-axis (probability of this class)\n",
        "class_to_plot = \"LumA\"                       # e.g., \"LumB\", \"Basal\", \"HER2\", \"Normal\"\n",
        "cidx = class_names.index(class_to_plot)      # class_names came from your LabelEncoder"
      ],
      "metadata": {
        "id": "MVNlng2GWVMx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.inspection import PartialDependenceDisplay, permutation_importance\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def _unwrap(est):\n",
        "    return est.named_steps[list(est.named_steps)[-1]] if hasattr(est, \"named_steps\") else est\n",
        "\n",
        "def _resp(est):\n",
        "    est = _unwrap(est)\n",
        "    return \"predict_proba\" if hasattr(est, \"predict_proba\") else \"decision_function\"\n",
        "\n",
        "def topk_features(estimator, X_ref, y_ref=None, k=9):\n",
        "    fin = _unwrap(estimator)\n",
        "    if hasattr(fin, \"feature_importances_\"):\n",
        "        w = np.asarray(fin.feature_importances_)\n",
        "    elif hasattr(fin, \"coef_\"):\n",
        "        w = np.mean(np.abs(np.asarray(fin.coef_)), axis=0)  # multiclass â†’ avg abs\n",
        "    else:\n",
        "        pi = permutation_importance(estimator, X_ref, y_ref, n_repeats=5, random_state=42, scoring=\"accuracy\")\n",
        "        w = pi.importances_mean\n",
        "    order = np.argsort(w)[::-1][:k]\n",
        "    return X_ref.columns[order].tolist()\n",
        "\n",
        "def plot_pdp_block_multi(model, X_ref, title, k=9, n_cols=3, grid=50):\n",
        "    feats = topk_features(model, X_ref, y_ref=y_tr, k=k)\n",
        "    disp = PartialDependenceDisplay.from_estimator(\n",
        "        model, X_ref, features=feats, kind=\"both\",\n",
        "        target=cidx, response_method=_resp(model),\n",
        "        grid_resolution=grid, n_jobs=-1\n",
        "    )\n",
        "    # match the old look: tight grid, minimal whitespace\n",
        "    n_rows = int(np.ceil(len(feats)/n_cols))\n",
        "    fig = plt.gcf()\n",
        "    fig.set_size_inches(5*n_cols, 2.8*n_rows)\n",
        "    fig.suptitle(f\"{title} â€” PDP + ICE (top {k} features)\", y=0.98, fontsize=12)\n",
        "    plt.tight_layout(rect=[0,0,1,0.95]); plt.show()\n",
        "    return feats"
      ],
      "metadata": {
        "id": "tyvZJ_w7WeNN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# assume models_rfe are already fitted on X_tr_rfe, y_tr\n",
        "rfe_lr_feats  = plot_pdp_block_multi(models_rfe[\"LogReg\"], X_tr_rfe, f\"Logistic Regression (RFE) â€” {class_to_plot}\")\n",
        "rfe_rf_feats  = plot_pdp_block_multi(models_rfe[\"RF\"],     X_tr_rfe, f\"Random Forest (RFE) â€” {class_to_plot}\")\n",
        "rfe_svm_feats = plot_pdp_block_multi(models_rfe[\"SVM\"],    X_tr_rfe, f\"SVM (RFE) â€” {class_to_plot}\")\n",
        "rfe_xgb_feats = plot_pdp_block_multi(models_rfe[\"XGB\"],    X_tr_rfe, f\"XGBoost (RFE) â€” {class_to_plot}\")\n",
        "rfe_mlp_feats = plot_pdp_block_multi(models_rfe[\"MLP\"],    X_tr_rfe, f\"MLP (RFE) â€” {class_to_plot}\")"
      ],
      "metadata": {
        "id": "hiIs6HOcWh_H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# assume models_lasso are already fitted on X_tr_las, y_tr\n",
        "las_lr_feats  = plot_pdp_block_multi(models_lasso[\"LogReg\"], X_tr_las, f\"Logistic Regression (LASSO) â€” {class_to_plot}\")\n",
        "las_rf_feats  = plot_pdp_block_multi(models_lasso[\"RF\"],     X_tr_las, f\"Random Forest (LASSO) â€” {class_to_plot}\")\n",
        "las_svm_feats = plot_pdp_block_multi(models_lasso[\"SVM\"],    X_tr_las, f\"SVM (LASSO) â€” {class_to_plot}\")\n",
        "las_xgb_feats = plot_pdp_block_multi(models_lasso[\"XGB\"],    X_tr_las, f\"XGBoost (LASSO) â€” {class_to_plot}\")\n",
        "las_mlp_feats = plot_pdp_block_multi(models_lasso[\"MLP\"],    X_tr_las, f\"MLP (LASSO) â€” {class_to_plot}\")"
      ],
      "metadata": {
        "id": "eEzf8PIGWjrj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## BASAL"
      ],
      "metadata": {
        "id": "Ipe7r4BRYIKB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# choose the subtype to visualize on the y-axis (probability of this class)\n",
        "class_to_plot = \"Basal\"                       # e.g., \"LumB\", \"Basal\", \"HER2\", \"Normal\"\n",
        "cidx = class_names.index(class_to_plot)      # class_names came from your LabelEncoder"
      ],
      "metadata": {
        "id": "k0vabTkuXnhb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.inspection import PartialDependenceDisplay, permutation_importance\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def _unwrap(est):\n",
        "    return est.named_steps[list(est.named_steps)[-1]] if hasattr(est, \"named_steps\") else est\n",
        "\n",
        "def _resp(est):\n",
        "    est = _unwrap(est)\n",
        "    return \"predict_proba\" if hasattr(est, \"predict_proba\") else \"decision_function\"\n",
        "\n",
        "def topk_features(estimator, X_ref, y_ref=None, k=9):\n",
        "    fin = _unwrap(estimator)\n",
        "    if hasattr(fin, \"feature_importances_\"):\n",
        "        w = np.asarray(fin.feature_importances_)\n",
        "    elif hasattr(fin, \"coef_\"):\n",
        "        w = np.mean(np.abs(np.asarray(fin.coef_)), axis=0)  # multiclass â†’ avg abs\n",
        "    else:\n",
        "        pi = permutation_importance(estimator, X_ref, y_ref, n_repeats=5, random_state=42, scoring=\"accuracy\")\n",
        "        w = pi.importances_mean\n",
        "    order = np.argsort(w)[::-1][:k]\n",
        "    return X_ref.columns[order].tolist()\n",
        "\n",
        "def plot_pdp_block_multi(model, X_ref, title, k=9, n_cols=3, grid=50):\n",
        "    feats = topk_features(model, X_ref, y_ref=y_tr, k=k)\n",
        "    disp = PartialDependenceDisplay.from_estimator(\n",
        "        model, X_ref, features=feats, kind=\"both\",\n",
        "        target=cidx, response_method=_resp(model),\n",
        "        grid_resolution=grid, n_jobs=-1\n",
        "    )\n",
        "    # match the old look: tight grid, minimal whitespace\n",
        "    n_rows = int(np.ceil(len(feats)/n_cols))\n",
        "    fig = plt.gcf()\n",
        "    fig.set_size_inches(5*n_cols, 2.8*n_rows)\n",
        "    fig.suptitle(f\"{title} â€” PDP + ICE (top {k} features)\", y=0.98, fontsize=12)\n",
        "    plt.tight_layout(rect=[0,0,1,0.95]); plt.show()\n",
        "    return feats"
      ],
      "metadata": {
        "id": "gS7wXlIuXzJf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# assume models_rfe are already fitted on X_tr_rfe, y_tr\n",
        "rfe_lr_feats  = plot_pdp_block_multi(models_rfe[\"LogReg\"], X_tr_rfe, f\"Logistic Regression (RFE) â€” {class_to_plot}\")\n",
        "rfe_rf_feats  = plot_pdp_block_multi(models_rfe[\"RF\"],     X_tr_rfe, f\"Random Forest (RFE) â€” {class_to_plot}\")\n",
        "rfe_svm_feats = plot_pdp_block_multi(models_rfe[\"SVM\"],    X_tr_rfe, f\"SVM (RFE) â€” {class_to_plot}\")\n",
        "rfe_xgb_feats = plot_pdp_block_multi(models_rfe[\"XGB\"],    X_tr_rfe, f\"XGBoost (RFE) â€” {class_to_plot}\")\n",
        "rfe_mlp_feats = plot_pdp_block_multi(models_rfe[\"MLP\"],    X_tr_rfe, f\"MLP (RFE) â€” {class_to_plot}\")"
      ],
      "metadata": {
        "id": "gPk4wtvqYAb4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# assume models_lasso are already fitted on X_tr_las, y_tr\n",
        "las_lr_feats  = plot_pdp_block_multi(models_lasso[\"LogReg\"], X_tr_las, f\"Logistic Regression (LASSO) â€” {class_to_plot}\")\n",
        "las_rf_feats  = plot_pdp_block_multi(models_lasso[\"RF\"],     X_tr_las, f\"Random Forest (LASSO) â€” {class_to_plot}\")\n",
        "las_svm_feats = plot_pdp_block_multi(models_lasso[\"SVM\"],    X_tr_las, f\"SVM (LASSO) â€” {class_to_plot}\")\n",
        "las_xgb_feats = plot_pdp_block_multi(models_lasso[\"XGB\"],    X_tr_las, f\"XGBoost (LASSO) â€” {class_to_plot}\")\n",
        "las_mlp_feats = plot_pdp_block_multi(models_lasso[\"MLP\"],    X_tr_las, f\"MLP (LASSO) â€” {class_to_plot}\")"
      ],
      "metadata": {
        "id": "DH5vcxAVYDn-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LumB"
      ],
      "metadata": {
        "id": "DpjCTuWsuDun"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# choose the subtype to visualize on the y-axis (probability of this class)\n",
        "class_to_plot = \"LumB\"                       # e.g., \"LumB\", \"Basal\", \"HER2\", \"Normal\"\n",
        "cidx = class_names.index(class_to_plot)      # class_names came from your LabelEncoder"
      ],
      "metadata": {
        "id": "TYoN9jbujh_h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.inspection import PartialDependenceDisplay, permutation_importance\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def _unwrap(est):\n",
        "    return est.named_steps[list(est.named_steps)[-1]] if hasattr(est, \"named_steps\") else est\n",
        "\n",
        "def _resp(est):\n",
        "    est = _unwrap(est)\n",
        "    return \"predict_proba\" if hasattr(est, \"predict_proba\") else \"decision_function\"\n",
        "\n",
        "def topk_features(estimator, X_ref, y_ref=None, k=9):\n",
        "    fin = _unwrap(estimator)\n",
        "    if hasattr(fin, \"feature_importances_\"):\n",
        "        w = np.asarray(fin.feature_importances_)\n",
        "    elif hasattr(fin, \"coef_\"):\n",
        "        w = np.mean(np.abs(np.asarray(fin.coef_)), axis=0)  # multiclass â†’ avg abs\n",
        "    else:\n",
        "        pi = permutation_importance(estimator, X_ref, y_ref, n_repeats=5, random_state=42, scoring=\"accuracy\")\n",
        "        w = pi.importances_mean\n",
        "    order = np.argsort(w)[::-1][:k]\n",
        "    return X_ref.columns[order].tolist()\n",
        "\n",
        "def plot_pdp_block_multi(model, X_ref, title, k=9, n_cols=3, grid=50):\n",
        "    feats = topk_features(model, X_ref, y_ref=y_tr, k=k)\n",
        "    disp = PartialDependenceDisplay.from_estimator(\n",
        "        model, X_ref, features=feats, kind=\"both\",\n",
        "        target=cidx, response_method=_resp(model),\n",
        "        grid_resolution=grid, n_jobs=-1\n",
        "    )\n",
        "    # match the old look: tight grid, minimal whitespace\n",
        "    n_rows = int(np.ceil(len(feats)/n_cols))\n",
        "    fig = plt.gcf()\n",
        "    fig.set_size_inches(5*n_cols, 2.8*n_rows)\n",
        "    fig.suptitle(f\"{title} â€” PDP + ICE (top {k} features)\", y=0.98, fontsize=12)\n",
        "    plt.tight_layout(rect=[0,0,1,0.95]); plt.show()\n",
        "    return feats"
      ],
      "metadata": {
        "id": "RBkeAjpat3qN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# assume models_rfe are already fitted on X_tr_rfe, y_tr\n",
        "rfe_lr_feats  = plot_pdp_block_multi(models_rfe[\"LogReg\"], X_tr_rfe, f\"Logistic Regression (RFE) â€” {class_to_plot}\")\n",
        "rfe_rf_feats  = plot_pdp_block_multi(models_rfe[\"RF\"],     X_tr_rfe, f\"Random Forest (RFE) â€” {class_to_plot}\")\n",
        "rfe_svm_feats = plot_pdp_block_multi(models_rfe[\"SVM\"],    X_tr_rfe, f\"SVM (RFE) â€” {class_to_plot}\")\n",
        "rfe_xgb_feats = plot_pdp_block_multi(models_rfe[\"XGB\"],    X_tr_rfe, f\"XGBoost (RFE) â€” {class_to_plot}\")\n",
        "rfe_mlp_feats = plot_pdp_block_multi(models_rfe[\"MLP\"],    X_tr_rfe, f\"MLP (RFE) â€” {class_to_plot}\")"
      ],
      "metadata": {
        "id": "DjCg_Vm_t7eP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# assume models_lasso are already fitted on X_tr_las, y_tr\n",
        "las_lr_feats  = plot_pdp_block_multi(models_lasso[\"LogReg\"], X_tr_las, f\"Logistic Regression (LASSO) â€” {class_to_plot}\")\n",
        "las_rf_feats  = plot_pdp_block_multi(models_lasso[\"RF\"],     X_tr_las, f\"Random Forest (LASSO) â€” {class_to_plot}\")\n",
        "las_svm_feats = plot_pdp_block_multi(models_lasso[\"SVM\"],    X_tr_las, f\"SVM (LASSO) â€” {class_to_plot}\")\n",
        "las_xgb_feats = plot_pdp_block_multi(models_lasso[\"XGB\"],    X_tr_las, f\"XGBoost (LASSO) â€” {class_to_plot}\")\n",
        "las_mlp_feats = plot_pdp_block_multi(models_lasso[\"MLP\"],    X_tr_las, f\"MLP (LASSO) â€” {class_to_plot}\")"
      ],
      "metadata": {
        "id": "oRkDwweqt_NB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "B5RLFfA-yjlE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}